2022-07-17 20:28:31,819:INFO: device: cuda:5 n_gpu: 8
2022-07-17 20:28:31,885:INFO: device: cuda:2 n_gpu: 8
2022-07-17 20:28:31,885:INFO: device: cuda:3 n_gpu: 8
2022-07-17 20:28:31,885:INFO: device: cuda:4 n_gpu: 8
2022-07-17 20:28:31,886:INFO: Effective parameters:
2022-07-17 20:28:31,886:INFO: device: cuda:1 n_gpu: 8
2022-07-17 20:28:31,886:INFO: device: cuda:7 n_gpu: 8
2022-07-17 20:28:31,886:INFO: device: cuda:6 n_gpu: 8
2022-07-17 20:28:31,886:INFO:   <<< batch_size: 128
2022-07-17 20:28:31,889:INFO:   <<< batch_size_val: 8
2022-07-17 20:28:31,889:INFO:   <<< best_ckpt_path: 
2022-07-17 20:28:31,889:INFO:   <<< cache_dir: 
2022-07-17 20:28:31,889:INFO:   <<< coef_lr: 0.001
2022-07-17 20:28:31,889:INFO:   <<< cross_model: cross-base
2022-07-17 20:28:31,889:INFO:   <<< cross_num_hidden_layers: 4
2022-07-17 20:28:31,889:INFO:   <<< data_path: /data/ceph_11015/ssd/jarvicliu/dataset/msrvtt/msrvtt_data/MSRVTT_data.json
2022-07-17 20:28:31,889:INFO:   <<< datatype: msrvtt
2022-07-17 20:28:31,889:INFO:   <<< do_eval: False
2022-07-17 20:28:31,889:INFO:   <<< do_lower_case: False
2022-07-17 20:28:31,889:INFO:   <<< do_pretrain: False
2022-07-17 20:28:31,896:INFO:   <<< do_train: True
2022-07-17 20:28:31,897:INFO:   <<< epochs: 5
2022-07-17 20:28:31,897:INFO:   <<< eval_frame_order: 0
2022-07-17 20:28:31,897:INFO:   <<< eval_in_train: True
2022-07-17 20:28:31,897:INFO:   <<< expand_msrvtt_sentences: True
2022-07-17 20:28:31,897:INFO:   <<< feature_framerate: 1
2022-07-17 20:28:31,897:INFO:   <<< features_path: /data/ceph_11015/ssd/jarvicliu/dataset/msrvtt/compressed_videos
2022-07-17 20:28:31,897:INFO:   <<< fp16: False
2022-07-17 20:28:31,897:INFO:   <<< fp16_opt_level: O1
2022-07-17 20:28:31,897:INFO:   <<< freeze_layer_num: 0
2022-07-17 20:28:31,897:INFO:   <<< gradient_accumulation_steps: 1
2022-07-17 20:28:31,907:INFO:   <<< hard_negative_rate: 0.5
2022-07-17 20:28:31,907:INFO:   <<< init_model: None
2022-07-17 20:28:31,907:INFO:   <<< linear_patch: 2d
2022-07-17 20:28:31,907:INFO:   <<< local_rank: 0
2022-07-17 20:28:31,909:INFO:   <<< loose_type: True
2022-07-17 20:28:31,909:INFO:   <<< lr: 0.0001
2022-07-17 20:28:31,909:INFO:   <<< lr_decay: 0.9
2022-07-17 20:28:31,909:INFO:   <<< margin: 0.1
2022-07-17 20:28:31,909:INFO:   <<< max_frames: 12
2022-07-17 20:28:31,909:INFO:   <<< max_words: 32
2022-07-17 20:28:31,909:INFO:   <<< n_display: 50
2022-07-17 20:28:31,909:INFO:   <<< n_gpu: 1
2022-07-17 20:28:31,909:INFO:   <<< n_pair: 1
2022-07-17 20:28:31,909:INFO:   <<< negative_weighting: 1
2022-07-17 20:28:31,915:INFO:   <<< num_thread_reader: 8
2022-07-17 20:28:31,915:INFO:   <<< output_dir: ckpts/msrvtt_test
2022-07-17 20:28:31,915:INFO:   <<< pretrained_clip_name: ViT-B/32
2022-07-17 20:28:31,917:INFO:   <<< rank: 0
2022-07-17 20:28:31,918:INFO:   <<< sampled_use_mil: False
2022-07-17 20:28:31,918:INFO:   <<< seed: 42
2022-07-17 20:28:31,918:INFO:   <<< sim_header: seqTransf
2022-07-17 20:28:31,918:INFO:   <<< slice_framepos: 2
2022-07-17 20:28:31,918:INFO:   <<< task_type: retrieval
2022-07-17 20:28:31,918:INFO:   <<< text_num_hidden_layers: 12
2022-07-17 20:28:31,918:INFO:   <<< train_csv: /data/ceph_11015/ssd/jarvicliu/dataset/msrvtt/msrvtt_data/MSRVTT_train.9k.csv
2022-07-17 20:28:31,918:INFO:   <<< train_frame_order: 0
2022-07-17 20:28:31,918:INFO:   <<< use_mil: False
2022-07-17 20:28:31,918:INFO:   <<< val_csv: /data/ceph_11015/ssd/jarvicliu/dataset/msrvtt/msrvtt_data/MSRVTT_JSFUSION_test.csv
2022-07-17 20:28:31,918:INFO:   <<< video_dim: 1024
2022-07-17 20:28:31,918:INFO:   <<< visual_num_hidden_layers: 12
2022-07-17 20:28:31,918:INFO:   <<< warmup_proportion: 0.1
2022-07-17 20:28:31,918:INFO:   <<< world_size: 8
2022-07-17 20:28:31,918:INFO: device: cuda:0 n_gpu: 8
2022-07-17 20:30:21,786:INFO: loading archive file /cfs/cfs-rmuhzak3/jarvicliu/github_public/ts2_net/modules/cross-base
2022-07-17 20:30:21,786:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 128,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2022-07-17 20:30:21,791:INFO: Weight doesn't exsits. /cfs/cfs-rmuhzak3/jarvicliu/github_public/ts2_net/modules/cross-base/cross_pytorch_model.bin
2022-07-17 20:30:21,792:WARNING: Stage-One:True, Stage-Two:False
2022-07-17 20:30:21,792:WARNING: Test retrieval by loose type.
2022-07-17 20:30:21,794:WARNING: 	 embed_dim: 512
2022-07-17 20:30:21,794:WARNING: 	 image_resolution: 224
2022-07-17 20:30:21,794:WARNING: 	 vision_layers: 12
2022-07-17 20:30:21,794:WARNING: 	 vision_width: 768
2022-07-17 20:30:21,794:WARNING: 	 vision_patch_size: 32
2022-07-17 20:30:21,794:WARNING: 	 context_length: 77
2022-07-17 20:30:21,797:WARNING: 	 vocab_size: 49408
2022-07-17 20:30:21,797:WARNING: 	 transformer_width: 512
2022-07-17 20:30:21,797:WARNING: 	 transformer_heads: 8
2022-07-17 20:30:21,797:WARNING: 	 transformer_layers: 12
2022-07-17 20:30:21,797:WARNING: 		 linear_patch: 2d
2022-07-17 20:30:21,800:WARNING: 	 cut_top_layer: 0
2022-07-17 20:30:23,052:WARNING: 	 sim_header: seqTransf
2022-07-17 20:30:30,036:WARNING: Using patch shift!
2022-07-17 20:30:30,037:WARNING: Using patch shift!
2022-07-17 20:30:30,040:WARNING: Using patch shift!
2022-07-17 20:30:30,041:WARNING: Using patch shift!
2022-07-17 20:30:30,055:WARNING: Using patch shift!
2022-07-17 20:30:30,055:WARNING: Using patch shift!
2022-07-17 20:30:30,062:INFO: --------------------
2022-07-17 20:30:30,062:INFO: Weights of CLIP4Clip not initialized from pretrained model: 
   visual_prompt_encoder.positional_embedding
   visual_prompt_encoder.conv1.weight
   visual_prompt_encoder.layer_norm.weight
   visual_prompt_encoder.layer_norm.bias
   visual_token_selector.score_predictor.in_conv.0.weight
   visual_token_selector.score_predictor.in_conv.0.bias
   visual_token_selector.score_predictor.in_conv.1.weight
   visual_token_selector.score_predictor.out_conv.0.weight
   visual_token_selector.score_predictor.out_conv.2.weight
   text_token_selector.score_predictor.in_conv.0.weight
   text_token_selector.score_predictor.in_conv.0.bias
   text_token_selector.score_predictor.in_conv.1.weight
   text_token_selector.score_predictor.in_conv.1.bias
   text_token_selector.score_predictor.out_conv.0.weight
   text_token_selector.score_predictor.out_conv.2.weight
2022-07-17 20:30:30,062:INFO: Weights from pretrained model not used in CLIP4Clip: 
   clip.input_resolution
   clip.context_length
   clip.vocab_size
2022-07-17 20:30:30,062:WARNING: Using patch shift!
2022-07-17 20:30:30,062:WARNING: Using patch shift!
2022-07-17 20:30:30,093:WARNING: Using patch shift!
2022-07-17 20:30:30,094:WARNING: Using patch shift!
2022-07-17 20:30:30,104:WARNING: Using patch shift!
2022-07-17 20:30:30,104:WARNING: Using patch shift!
2022-07-17 20:30:30,106:WARNING: Using patch shift!
2022-07-17 20:30:30,108:WARNING: Using patch shift!
2022-07-17 20:30:30,108:WARNING: Using patch shift!
2022-07-17 20:30:30,108:WARNING: Using patch shift!
2022-07-17 20:30:34,885:INFO: ***** Running test *****
2022-07-17 20:30:34,885:INFO:   Num examples = 1000
2022-07-17 20:30:34,885:INFO:   Batch size = 8
2022-07-17 20:30:34,885:INFO:   Num steps = 125
2022-07-17 20:30:34,885:INFO: ***** Running val *****
2022-07-17 20:30:34,885:INFO:   Num examples = 1000
2022-07-17 20:30:58,619:INFO: ***** Running training *****
2022-07-17 20:30:58,620:INFO:   Num examples = 180000
2022-07-17 20:30:58,620:INFO:   Batch size = 128
2022-07-17 20:30:58,620:INFO:   Num steps = 7030
2022-07-17 20:34:04,291:INFO: Epoch: 1/5, Step: 50/1406, Lr: 0.000000007-0.000007112, Loss: 1.582253, Time/step: 3.713406
